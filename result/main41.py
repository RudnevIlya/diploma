import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    confusion_matrix, ConfusionMatrixDisplay, classification_report
)
from imblearn.over_sampling import RandomOverSampler
from lightgbm import LGBMClassifier
import matplotlib.pyplot as plt

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ===
df = pd.read_csv("final_merged_output_with_bert.csv")
df = df[df["Rating"] >= 1]

# === –ë–∏–Ω–∞—Ä–Ω–∞—è —Ü–µ–ª—å: 1 ‚Äî –≤—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥, 0 ‚Äî –æ—Å—Ç–∞–ª—å–Ω–æ–µ
df["Target"] = (df["Rating"] >= 4.25).astype(int)

features = [
    "Emotional", "AvgSentenceLength", "Average_TFIDF", "HD_D",
    "ExclamationCount", "AbstractNounRatio", "AdjRatio", "VerbRatio",
    "SimLow", "SimMid", "SimHigh"
]

df = df.dropna(subset=features + ["Target"])
X = df[features].values
y = df["Target"]

# === –†–∞–∑–±–∏–µ–Ω–∏–µ
splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_idx, test_idx in splitter.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

# === –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)

# === –û–±—É—á–µ–Ω–∏–µ
model = LGBMClassifier(
    random_state=42,
    n_estimators=300,
    learning_rate=0.05,
    max_depth=5
)
model.fit(X_train_resampled, y_train_resampled)
y_pred = model.predict(X_test)

# === –ú–µ—Ç—Ä–∏–∫–∏
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("\nüìä === –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –í—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥ ===")
print(f"üéØ Accuracy:       {acc:.4f}")
print(f"üìé F1 Score:       {f1:.4f}")
print(f"üìå Precision:      {precision:.4f}")
print(f"üìà Recall:         {recall:.4f}")
print("\nüìù Classification Report:")
print(classification_report(y_test, y_pred, target_names=["–Ω–µ –≤—ã—Å–æ–∫–∏–π", "–≤—ã—Å–æ–∫–∏–π"]))

# === –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["–Ω–µ –≤—ã—Å–æ–∫–∏–π", "–≤—ã—Å–æ–∫–∏–π"])
disp.plot(cmap="Greens", values_format="d")
plt.title("Confusion Matrix ‚Äî –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score

# === –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
y_proba = model.predict_proba(X_test)[:, 1]  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å "–≤—ã—Å–æ–∫–∏–π"

# === –ú–∞—Å—Å–∏–≤ –ø–æ—Ä–æ–≥–æ–≤
thresholds = np.linspace(0.0, 1.0, 101)

precisions = []
recalls = []
f1s = []

for t in thresholds:
    y_pred_thresh = (y_proba >= t).astype(int)
    precisions.append(precision_score(y_test, y_pred_thresh, zero_division=0))
    recalls.append(recall_score(y_test, y_pred_thresh, zero_division=0))
    f1s.append(f1_score(y_test, y_pred_thresh, zero_division=0))

# === –ù–∞–π–¥—ë–º –ª—É—á—à–∏–π f1
best_idx = np.argmax(f1s)
best_threshold = thresholds[best_idx]

print(f"‚≠ê –õ—É—á—à–∏–π F1 = {f1s[best_idx]:.3f} –ø—Ä–∏ threshold = {best_threshold:.2f}")
print(f"üîé Precision = {precisions[best_idx]:.3f}, Recall = {recalls[best_idx]:.3f}")

# === –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.plot(thresholds, precisions, label="Precision", linestyle='--')
plt.plot(thresholds, recalls, label="Recall", linestyle='-.')
plt.plot(thresholds, f1s, label="F1 Score", linewidth=2)

plt.axvline(best_threshold, color='gray', linestyle=':', label=f"Best Threshold = {best_threshold:.2f}")
plt.xlabel("–ü–æ—Ä–æ–≥ (threshold)")
plt.ylabel("–ú–µ—Ç—Ä–∏–∫–∞")
plt.title("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å Precision / Recall / F1 –æ—Ç –ø–æ—Ä–æ–≥–∞")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

threshold = 0.75  # –∏–ª–∏ –¥—Ä—É–≥–æ–π, –∏—Å—Ö–æ–¥—è –∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞
y_proba = model.predict_proba(X_test)[:, 1]

# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –Ω–æ–≤–æ–º—É –ø–æ—Ä–æ–≥—É
y_pred_custom = (y_proba >= threshold).astype(int)

# –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score

print(f"\n‚öôÔ∏è –ü–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {threshold}")
print("üéØ Accuracy:", accuracy_score(y_test, y_pred_custom))
print("üìà Recall:", recall_score(y_test, y_pred_custom))
print("üìå Precision:", precision_score(y_test, y_pred_custom))
print("üìé F1 Score:", f1_score(y_test, y_pred_custom))

print("\nüìù Classification Report:")
print(classification_report(y_test, y_pred_custom, digits=3))

import numpy as np
from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# === y_test ‚Äî –Ω–∞—Å—Ç–æ—è—â–∏–µ –º–µ—Ç–∫–∏ (–º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å)
# === y_proba ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –æ—Ç model.predict_proba(X_test)
# shape: (n_samples, 3)

threshold_high = 0.75  # –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∞ "–≤—ã—Å–æ–∫–∏–π" (–∏–Ω–¥–µ–∫—Å 2)

# === –ö–∞—Å—Ç–æ–º–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º "–≤—ã—Å–æ–∫–∏–π"
y_pred_custom = []

for probs in y_proba:
    if probs[2] >= threshold_high:
        y_pred_custom.append(2)  # "–≤—ã—Å–æ–∫–∏–π"
    else:
        y_pred_custom.append(np.argmax(probs[:2]))  # –≤—ã–±–∏—Ä–∞–µ–º –º–µ–∂–¥—É "–Ω–∏–∑–∫–∏–π" (0) –∏ "—Å—Ä–µ–¥–Ω–∏–π" (1)

y_pred_custom = np.array(y_pred_custom)

# === –ú–µ—Ç—Ä–∏–∫–∏
print(f"\nüìä === –¢—Ä—ë—Ö–∫–ª–∞—Å—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ—Ä–æ–≥–æ–º –¥–ª—è '–≤—ã—Å–æ–∫–∏–π' (‚â• {threshold_high}) ===")
print("üéØ Accuracy:", accuracy_score(y_test, y_pred_custom))
print("üìä F1 Macro:", f1_score(y_test, y_pred_custom, average="macro"))
print("üìä F1 Weighted:", f1_score(y_test, y_pred_custom, average="weighted"))
print("‚öñÔ∏è Balanced Accuracy:", balanced_accuracy_score(y_test, y_pred_custom))
print("\nüìù Classification Report:")
print(classification_report(
    y_test, y_pred_custom,
    target_names=["–Ω–∏–∑–∫–∏–π", "—Å—Ä–µ–¥–Ω–∏–π", "–≤—ã—Å–æ–∫–∏–π"],
    digits=3
))

# === –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
cm = confusion_matrix(y_test, y_pred_custom)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["–Ω–∏–∑–∫–∏–π", "—Å—Ä–µ–¥–Ω–∏–π", "–≤—ã—Å–æ–∫–∏–π"], yticklabels=["–Ω–∏–∑–∫–∏–π", "—Å—Ä–µ–¥–Ω–∏–π", "–≤—ã—Å–æ–∫–∏–π"])
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Confusion Matrix (—Å –ø–æ—Ä–æ–≥–æ–º –¥–ª—è '–≤—ã—Å–æ–∫–∏–π')")
plt.tight_layout()
plt.show()
