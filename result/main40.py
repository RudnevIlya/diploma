import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.utils.class_weight import compute_class_weight
from catboost import CatBoostClassifier
import matplotlib.pyplot as plt

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
df = pd.read_csv("final_merged_output_with_bert.csv")
df = df[df["Rating"] >= 1]

# === –ì—Ä–∞–Ω–∏—Ü—ã –∫–ª–∞—Å—Å–æ–≤ ===
# class_ranges = {
#     "–Ω–∏–∑–∫–∏–π":   (0, 3.85),
#     "—Å—Ä–µ–¥–Ω–∏–π":  (3.85, 4.25),
#     "–≤—ã—Å–æ–∫–∏–π":  (4.25, 5.01)
# }

class_ranges = {
    "–Ω–∏–∑–∫–∏–π":   (0, 3.85),
    "—Å—Ä–µ–¥–Ω–∏–π":  (3.85, 4.25),
    "–≤—ã—Å–æ–∫–∏–π":  (4.25, 5.01)
}

class_names = list(class_ranges.keys())

def rating_to_class(rating):
    for idx, (label, (low, high)) in enumerate(class_ranges.items()):
        if low <= rating < high:
            return idx
    return len(class_ranges) - 1

# === –ü—Ä–∏–∑–Ω–∞–∫–∏ ===
manual_features = [
    "HD_D", "Average_TFIDF", "Emotional", "Length",
    "AvgWordLength", "AvgSentenceLength", "LongWordRatio",
    "LexicalDiversity", "SentimentScore", "VerbRatio","AdjRatio","QuotesCount","NegationCount","ExclamationCount","AbstractNounRatio"
]
cosine_features = ["SimLow", "SimMid", "SimHigh"]
features = manual_features + cosine_features

# features = [
# "Emotional",
#     "AvgWordLength", "AvgSentenceLength",
#     "LexicalDiversity", "SentimentScore", "VerbRatio","AdjRatio","AbstractNounRatio",
#     "SimLow", "SimMid", "SimHigh"
    
# ]

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
df = df.dropna(subset=features + ["Rating"])
X = df[features]
y = df["Rating"].apply(rating_to_class)

# === –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# === –†–∞–∑–±–∏–µ–Ω–∏–µ ===
splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_idx, test_idx in splitter.split(X_scaled, y):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

# === –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ ===
class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y_train), y=y_train)
print(class_weights)

# === –û–±—É—á–µ–Ω–∏–µ ===
clf = CatBoostClassifier(verbose=0, class_weights=class_weights, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# === –ú–µ—Ç—Ä–∏–∫–∏ ===
print("üìä === –ú–æ–¥–µ–ª—å: –†—É—á–Ω—ã–µ + –ö–æ—Å–∏–Ω—É—Å–Ω—ã–µ BERT-–ø—Ä–∏–∑–Ω–∞–∫–∏ ===")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=class_names, digits=3, zero_division=0))

# === –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ ===
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix (Manual + Cosine BERT)")
plt.tight_layout()
plt.show()

# === –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
importances = clf.get_feature_importance()
print("\nüìå –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for name, imp in sorted(zip(features, importances), key=lambda x: -x[1]):
    print(f"{name}: {imp:.4f}")

from sklearn.metrics import f1_score, balanced_accuracy_score

# === –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è accuracy
acc = accuracy_score(y_test, y_pred)
print(f"\nüéØ Accuracy: {acc:.4f}")

# === F1-–º–µ—Ç—Ä–∏–∫–∏
f1_macro = f1_score(y_test, y_pred, average="macro", zero_division=0)
f1_weighted = f1_score(y_test, y_pred, average="weighted", zero_division=0)

print(f"üìä F1 Macro:     {f1_macro:.4f}")
print(f"üìä F1 Weighted:  {f1_weighted:.4f}")

# === Balanced Accuracy
bal_acc = balanced_accuracy_score(y_test, y_pred)
print(f"‚öñÔ∏è Balanced Accuracy: {bal_acc:.4f}")
