import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import (
    accuracy_score, f1_score, balanced_accuracy_score,
    classification_report, confusion_matrix, ConfusionMatrixDisplay
)
from lightgbm import LGBMClassifier
import matplotlib.pyplot as plt

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
df = pd.read_csv("final_merged_output_with_bert.csv")
df = df[df["Rating"] >= 1]

# === 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ ===
class_ranges = {
    "–Ω–∏–∑–∫–∏–π": (0, 3.85),
    "—Å—Ä–µ–¥–Ω–∏–π": (3.85, 4.25),
    "–≤—ã—Å–æ–∫–∏–π": (4.25, 5.01)
}
class_names = list(class_ranges.keys())

def rating_to_class(r):
    for idx, (name, (lo, hi)) in enumerate(class_ranges.items()):
        if lo <= r < hi:
            return idx
    return len(class_ranges) - 1

df["Class"] = df["Rating"].apply(rating_to_class)

# === 3. –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
features = [
"HD_D", "Average_TFIDF", "Emotional",
    "AvgWordLength", "AvgSentenceLength", "LongWordRatio",
    "LexicalDiversity", "SentimentScore", "VerbRatio","AdjRatio","AbstractNounRatio"
]
# features = [
# "HD_D", "Average_TFIDF", "Emotional", "Length",
#     "AvgWordLength", "AvgSentenceLength", "LongWordRatio",
#     "LexicalDiversity", "SentimentScore", "VerbRatio","AdjRatio","QuotesCount","NegationCount","ExclamationCount","AbstractNounRatio"
# ]
df = df.dropna(subset=features + ["Class"])

X = df[features].values
y = df["Class"].values

# === 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test ===
splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_idx, test_idx in splitter.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

# === 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
model = LGBMClassifier(
    random_state=42,
    n_estimators=300,
    learning_rate=0.05,
    max_depth=5
)
model.fit(X_train, y_train)

# === 6. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
y_proba = model.predict_proba(X_test)

# === 7. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–ª—è "–≤—ã—Å–æ–∫–∏–π"
threshold_high = 0.35
y_pred_custom = []

for probs in y_proba:
    if probs[2] >= threshold_high:
        y_pred_custom.append(2)
    else:
        y_pred_custom.append(np.argmax(probs[:2]))

y_pred_custom = np.array(y_pred_custom)

# === 8. –ú–µ—Ç—Ä–∏–∫–∏
print(f"\nüìä === –ú–æ–¥–µ–ª—å —Å –ø–æ—Ä–æ–≥–æ–º ‚â• {threshold_high} –¥–ª—è '–≤—ã—Å–æ–∫–∏–π' ===")
print("üéØ Accuracy:", accuracy_score(y_test, y_pred_custom))
print("üìä F1 Macro:", f1_score(y_test, y_pred_custom, average='macro'))
print("üìä F1 Weighted:", f1_score(y_test, y_pred_custom, average='weighted'))
print("‚öñÔ∏è Balanced Accuracy:", balanced_accuracy_score(y_test, y_pred_custom))
print("\nüìù Classification Report:")
print(classification_report(y_test, y_pred_custom, target_names=class_names, digits=3))

# === 9. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
cm = confusion_matrix(y_test, y_pred_custom)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap="Blues", values_format="d")
plt.title(f"Confusion Matrix (–ø–æ—Ä–æ–≥ {threshold_high} –¥–ª—è '–≤—ã—Å–æ–∫–∏–π')")
plt.tight_layout()
plt.show()
