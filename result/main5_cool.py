import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

RATING_STEP = 0.1

# === Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… ===
df = pd.read_csv("merged_results.csv")
df = df[df["Rating"] >= 4]
df = df[df["Rating"] <= 5]

# ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ñ ÑˆÐ°Ð³Ð¾Ð¼ 0.1
df["Rating_class"] = df["Rating"].apply(lambda x: round(x / RATING_STEP) * RATING_STEP)
unique_classes = sorted(df["Rating_class"].unique())
class_to_idx = {v: i for i, v in enumerate(unique_classes)}
idx_to_class = {i: v for v, i in class_to_idx.items()}
df["Class_idx"] = df["Rating_class"].map(class_to_idx)

features = ["HD_D", "Average_TFIDF", "Value", "Length"]
X = df[features].values
y = df["Class_idx"].values
num_classes = len(unique_classes)

# Train/test split Ð¸ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð² Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹ Ð¸ Ð½Ð° ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)
y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)

# ÐœÐ¾Ð´ÐµÐ»ÑŒ
class MLPClassifier(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, output_dim)
        )

    def forward(self, x):
        return self.net(x)

model = MLPClassifier(X.shape[1], num_classes).to(device)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)

# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
for epoch in range(200):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train_tensor)
    loss = loss_fn(outputs, y_train_tensor)
    loss.backward()
    optimizer.step()
    if (epoch + 1) % 50 == 0:
        print(f"Epoch {epoch+1}/200 - Loss: {loss.item():.4f}")

# ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
model.eval()
with torch.no_grad():
    logits = model(X_test_tensor)
    preds = torch.argmax(logits, dim=1).cpu().numpy()
    probs = torch.softmax(logits, dim=1).cpu().numpy()
    true = y_test_tensor.cpu().numpy()

# ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
acc = accuracy_score(true, preds)
top2 = top_k_accuracy_score(true, probs, k=2, labels=list(range(num_classes)))
print(f"\nâœ… Accuracy: {acc:.4f}")
print(f"âœ… Top-2 Accuracy: {top2:.4f}")
print("\nðŸ“Š Classification Report:")
print(classification_report(
    true,
    preds,
    target_names=[str(idx_to_class[i]) for i in range(num_classes)],
    labels=list(range(num_classes)),
    zero_division=0
))


# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
df_preds = pd.DataFrame({
    "TrueRating": [idx_to_class[i] for i in true],
    "PredictedRating": [idx_to_class[i] for i in preds]
})
df_preds.to_csv("predictions.csv", index=False)
print("ðŸ“ ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² predictions.csv")

# ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº
cm = confusion_matrix(true, preds, labels=list(range(num_classes)))
plt.figure(figsize=(12, 8))
sns.heatmap(cm, annot=True, fmt="d", xticklabels=unique_classes, yticklabels=unique_classes, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix (Rating Class)")
plt.tight_layout()
plt.savefig("confusion_matrix.png")
print("ðŸ“Š ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² confusion_matrix.png")
